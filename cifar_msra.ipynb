{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Classifying tiny images with a Convolutional Neural Network\n",
    "======================================\n",
    "\n",
    "Outline\n",
    "------------------------\n",
    "This interactive notebook shows how to do image classification with a Convnet. You can edit code in the code cells, and run it with `Shift+Return`. The notebook is read-only, so feel free to hack the code, and reload the page if something breaks. The tutorial covers how to:\n",
    "* Build a small convNet in neon.\n",
    "* Train it on the [Cifar10](https://www.kaggle.com/c/cifar-10) dataset. \n",
    "* Upload a new image, and classify it into one of the 10 categories.\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/3649/media/cifar-10.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a model\n",
    "==================\n",
    "The pieces we need to set up a model are described in the [neon user guide](http://neon.nervanasys.com/docs/latest/index.html):\n",
    "* The CIFAR10 dataset.\n",
    "* layer configuration and a  [model](http://neon.nervanasys.com/docs/latest/models.html).\n",
    "* a compute [backend](http://neon.nervanasys.com/docs/latest/backends.html).\n",
    "* an [optimizer](http://neon.nervanasys.com/docs/latest/optimizers.html) to train the model.\n",
    "* [callbacks](http://neon.nervanasys.com/docs/latest/callbacks.html) to keep us updated about the progress of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neon.backends.nervanagpu:Neon is highly optimized for Maxwell GPUs. Although you might get speedups over CPUs, note that you are running on a pre-Maxwell GPU and you might not experience the fastest performance. For faster performance using the Nervana Cloud contact info@nervanasys.com\n"
     ]
    }
   ],
   "source": [
    "# Start by generating the backend:\n",
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='gpu',             \n",
    "                 batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a dataset\n",
    "-----------------\n",
    "More details about loading and generating datasets in our [documentation](http://neon.nervanasys.com/docs/latest/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ImageLoader serves images with random crops and scaling. \n",
    "# To prepocess the data with batch_writer.py, run:\n",
    "# batch_writer.py --set_type cifar10 --data_dir <path-to-save-batches>\n",
    "#                 --macro_size 10000 --target_size 40\n",
    "from neon.data import ImageLoader\n",
    "imgset_options = dict(inner_size=32, scale_range=40, aspect_ratio=110,\n",
    "                 repo_dir='/var/neon/data/cifar10', subset_pct=100)\n",
    "train_set = ImageLoader(set_name='train', shuffle=True, \n",
    "                        do_transforms=True, **imgset_options)\n",
    "test_set = ImageLoader(set_name='validation', shuffle=False, \n",
    "                       do_transforms=False, **imgset_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating layers\n",
    "The core of the model is the layers. This can be as simple as a list, but merging and branching makes it easy to specify complex topologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from neon.initializers import Uniform\n",
    "from neon.transforms import Rectlin, Softmax\n",
    "from neon.layers import Activation, Conv, Pooling, Affine, MergeSum\n",
    "\n",
    "# This is a simple convnet with a one conv layer,\n",
    "# max-pooling, and a fully connected layer. \n",
    "#\n",
    "# input - Conv - ReLu - Pooling - Affine - ReLu - Affine - Softmax\n",
    "#\n",
    "layers = [Conv((5, 5, 16), init=Uniform(-0.1, 0.1), activation=Rectlin()),\n",
    "          Pooling((2, 2)),\n",
    "          Affine(nout=500, init=Uniform(-0.1, 0.1), activation=Rectlin()),\n",
    "          Affine(nout=10, init=Uniform(-0.1, 0.1), activation=Softmax())]\n",
    "\n",
    "# We can use a MergeSum layer to combine differnt layers in parallel\n",
    "#\n",
    "#             - Conv3 - ReLu - \n",
    "#           /                  \\\n",
    "# input   -                     Sum - ReLu - ...\n",
    "#           \\                  /\n",
    "#             - Conv5 - ReLu - \n",
    "#\n",
    "conv3 = Conv((3, 3, 16), init=Uniform(-0.1, 0.1), activation=Rectlin())\n",
    "conv5 = Conv((5, 5, 16), padding=1, init=Uniform(-0.1, 0.1), activation=Rectlin())\n",
    "\n",
    "\n",
    "layers = [MergeSum([conv3, conv5]), Activation(Rectlin()),\n",
    "          Pooling((2, 2)),\n",
    "          Affine(nout=500, init=Uniform(-0.1, 0.1), activation=Rectlin()),\n",
    "          Affine(nout=10, init=Uniform(-0.1, 0.1), activation=Softmax())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Deep Residual Network\n",
    "A resnet module is a MergeSum layer containing a main path with conv layers, and a side path with a SkipNode() configured as the identity function. This allows earlier layer activations to bypass a series of layers.\n",
    "\n",
    "We use some helper functions to succinclty define the deep network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.initializers import Kaiming, IdentityInit\n",
    "from neon.layers import SkipNode\n",
    "from neon.models import Model\n",
    "\n",
    "# helper functions simplify init params for conv and identity layers\n",
    "def conv_params(fsize, nfm, stride=1, relu=True, batch_norm=True):\n",
    "    return dict(fshape=(fsize, fsize, nfm), \n",
    "                strides=stride, \n",
    "                padding=(1 if fsize > 1 else 0),\n",
    "                activation=(Rectlin() if relu else None),\n",
    "                init=Kaiming(local=True),\n",
    "                batch_norm=batch_norm)\n",
    "\n",
    "def id_params(nfm):\n",
    "    return dict(fshape=(1, 1, nfm), \n",
    "                strides=2, \n",
    "                padding=0, \n",
    "                activation=None, \n",
    "                init=IdentityInit())\n",
    "\n",
    "# A resnet module\n",
    "#\n",
    "#             - Conv - Conv - \n",
    "#           /                \\\n",
    "# input   -                   Sum - Relu - output\n",
    "#           \\               /\n",
    "#            -  Identity - \n",
    "#\n",
    "def module_factory(nfm, stride=1):\n",
    "    mainpath = [Conv(**conv_params(3, nfm, stride=stride)),\n",
    "                Conv(**conv_params(3, nfm, relu=False))]\n",
    "    sidepath = [SkipNode() if stride == 1 else Conv(**id_params(nfm))]\n",
    "\n",
    "    module = [MergeSum([mainpath, sidepath]),\n",
    "              Activation(Rectlin())]\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a collection of resnet modules between an input conv and output pooling and affine layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set depth = 3 for quick results \n",
    "# or depth = 9 to reach 6.7% top1 error in 150 epochs\n",
    "depth = 3\n",
    "nfms = [2**(stage + 4) for stage in sorted(range(3) * depth)]\n",
    "strides = [1] + [1 if cur == prev else 2 for cur, prev in zip(nfms[1:], nfms[:-1])]\n",
    "\n",
    "layers = [Conv(**conv_params(3, 16))]\n",
    "for nfm, stride in zip(nfms, strides):\n",
    "    layers.append(module_factory(nfm, stride))\n",
    "layers.append(Pooling('all', op='avg'))\n",
    "layers.append(Affine(10, init=Kaiming(local=False), \n",
    "                     batch_norm=True, activation=Softmax()))\n",
    "model = Model(layers=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function\n",
    "--------------\n",
    "The cost function compares network outputs with ground truth labels, and produces and error that we can backpropagate through the layers of the network.\n",
    "\n",
    "For our binary classification task, we use a cross entropy cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.transforms import CrossEntropyMulti\n",
    "from neon.layers import GeneralizedCost\n",
    "\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "---------\n",
    "We now have a cost function to minimize by gradient descent. We do this\n",
    "iteratively over small batches of the data set, making it stochastic gradient \n",
    "decesent (SGD). There are other [optimizers](http://neon.nervanasys.com/docs/latest/optimizers.html) such as RMSProp and AdaDelta that are supported in neon, but often simple gradient descent works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.optimizers import GradientDescentMomentum, Schedule\n",
    "\n",
    "opt = GradientDescentMomentum(0.1, 0.9, wdecay=0.0001, \n",
    "                              schedule=Schedule([90, 135], 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks\n",
    "---------\n",
    "To provide feedback while the model is training, neon lets the user specify a set of callbacks that get evaluated at the end of every iteration (minibatch) or pass through the dataset (epoch). Callbacks include evaluating the model on a validation set or computing missclassification percentage. There are also callbacks for saving to disk and for generating visualizations. Here we will set up a progress bar to monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up callbacks. By default sets up a progress bar\n",
    "from neon.transforms import Misclassification\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "\n",
    "valmetric = Misclassification()\n",
    "callbacks = Callbacks(model, eval_set=test_set, metric=valmetric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "Now all the pieces are in place to run the network. We use the fit function and pass it a dataset, cost, optmizer, and the callbacks we set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "must use initialized bsum config",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d2fb4ac2d758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit(train_set, optimizer=opt, num_epochs=epochs, \n\u001b[1;32m----> 4\u001b[1;33m           cost=cost, callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/neon/neon/models/model.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, cost, optimizer, num_epochs, callbacks)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epoch_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/models/model.pyc\u001b[0m in \u001b[0;36m_epoch_fit\u001b[1;34m(self, dataset, callbacks)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_to_optimize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/models/model.pyc\u001b[0m in \u001b[0;36mbprop\u001b[1;34m(self, delta)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDerivative\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/layers/container.pyc\u001b[0m in \u001b[0;36mbprop\u001b[1;34m(self, error, alpha, beta)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevert_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/layers/container.pyc\u001b[0m in \u001b[0;36mbprop\u001b[1;34m(self, error, alpha, beta)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/layers/container.pyc\u001b[0m in \u001b[0;36mbprop\u001b[1;34m(self, error, alpha, beta)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevert_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/layers/layer.pyc\u001b[0m in \u001b[0;36mbprop\u001b[1;34m(self, error, alpha, beta)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             self.be.bprop_conv(self.nglayer, self.W, error, self.deltas,\n\u001b[1;32m--> 654\u001b[1;33m                                alpha=alpha, beta=beta)\n\u001b[0m\u001b[0;32m    655\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnglayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/backends/nervanagpu.pyc\u001b[0m in \u001b[0;36mbprop_conv\u001b[1;34m(self, layer, F, E, grad_I, alpha, beta, bsum, repeat)\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizeI\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrad_I\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop_kernels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_I\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bprop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbprop_kernels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/neon/neon/backends/convolution.pyc\u001b[0m in \u001b[0;36mbind_params\u001b[1;34m(self, I, F, O, alpha, beta, bsum, flags)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbsum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mbsum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"must use initialized bsum config\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mbsum_gpudata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_bsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: must use initialized bsum config"
     ]
    }
   ],
   "source": [
    "# And  run the model\n",
    "epochs = 10\n",
    "model.fit(train_set, optimizer=opt, num_epochs=epochs, \n",
    "          cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! If you made it this far you have trained a convolutional network in neon.\n",
    "\n",
    "Evaluating the model\n",
    "--------------------\n",
    "We can now compute the misclassification on the test set to see how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the performance on the supplied test set\n",
    "from neon.transforms import Misclassification\n",
    "\n",
    "error_pct = 100 * model.eval(test_set, metric=Misclassification())\n",
    "print 'Misclassification error = %.1f%%' % error_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the depth of the network and the number of epochs, we can improve the performance to match state of the art.\n",
    "\n",
    "This was quite a lot of code! Generally, to set up a new model from scratch it is best to follow one of the examples from the neon/examples directory. It's easy to mix and match parts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference\n",
    "=========\n",
    "Now we want to grab a few new images from the internet and classify them through our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# download images from the web\n",
    "imgs = {\n",
    "       'frog': \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Atelopus_zeteki1.jpg/440px-Atelopus_zeteki1.jpg\",\n",
    "       'airplane': \"https://img0.etsystatic.com/016/0/5185796/il_570xN.433414910_p5n3.jpg\",\n",
    "       'cat': \"https://s-media-cache-ak0.pinimg.com/236x/8e/d7/41/8ed7410285f101ba5892ff723c91fa75.jpg\",\n",
    "       'car': \"http://static01.nyt.com/images/2012/09/09/automobiles/09REFI2/09REFI2-articleLarge.jpg\",\n",
    "       }\n",
    "\n",
    "# empty buffer to use for inference dataset\n",
    "# dims [minibatch, imgsize]\n",
    "x_new = np.zeros((128, 32*32*3), dtype=np.float32)\n",
    "\n",
    "# crop/resize images and assign them to slots in x_new\n",
    "# also display with true labels\n",
    "plt.figure(1)\n",
    "for i, name in enumerate(imgs):\n",
    "    imgs[name] = urllib.urlretrieve(imgs[name], filename=\"img/{}.jpg\".format(name))\n",
    "    plt.subplot(100 + (10 * len(imgs)) + 1 + i)\n",
    "\n",
    "    img = Image.open(\"img/{}.jpg\".format(name))\n",
    "    crop = img.crop((0,0,min(img.size),min(img.size)))\n",
    "    crop.thumbnail((32, 32))\n",
    "\n",
    "    plt.imshow(crop, interpolation=\"nearest\")\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "\n",
    "    x_new[i,:] = np.asarray(crop, dtype=np.float32)[:,:,(2,0,1)].transpose(2,0,1).reshape(1,3072) -127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset with this image for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.data import ArrayIterator\n",
    "\n",
    "# create a minibatch with the new image \n",
    "inference_set = ArrayIterator(x_new, None, nclass=10, \n",
    "                             lshape=(3, 32, 32))\n",
    "# inference_set = ArrayIterator(x_train, None, nclass=10, \n",
    "#                              lshape=(3, 32, 32))\n",
    "classes =[\"airplane\", \"auto\", \"bird\", \"cat\", \"deer\", \n",
    "          \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "out = model.get_outputs(inference_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model outputs on the inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "for i, name in enumerate(imgs):\n",
    "    plt.subplot(100 + (10 * len(imgs)) + 1 + i)\n",
    "\n",
    "    img = Image.open(\"img/{}.jpg\".format(name))\n",
    "    crop = img.crop((0,0,min(img.size),min(img.size)))\n",
    "    crop.thumbnail((32, 32))\n",
    "\n",
    "    title = \"{} ({:.2})\".format(classes[out[i].argmax()], out[i].max())\n",
    "        \n",
    "    plt.imshow(crop, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
