{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some notes:\n",
    "============\n",
    "\n",
    "to install this thing:\n",
    "---------------------\n",
    "* create AMI on https://nervana.signin.aws.amazon.com/console\n",
    "* sudo apt-get update\n",
    "* sudo apt-get install git make python-pip python-dev libhdf5-dev\n",
    "* sudo pip install virtualenv\n",
    "* git clone https://github.com/NervanaSystems/neon.git\n",
    "* cd neon; make; . .venv/bin/activate\n",
    "* pip install ipython jupyter matplotlib\n",
    "* ipython notebook --ip 0.0.0.0 --no-browser\n",
    "\n",
    "and you are in business!\n",
    "\n",
    "to connect to the notebook from outside:\n",
    "* add custom TCP rule to open port 8888"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[TODO]\n",
    "----\n",
    "[DONE] classify own image\n",
    "[TODO] mutli-cpu on AWS?\n",
    "[DONE] for demo run with GPU on max2?\n",
    "[TODO] Callback bug fix into master\n",
    "[TODO] Remove or fix weight visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started with neon\n",
    "=========================\n",
    "This notebook is a tutorial for neon beginners. It helps you specify a small convNet model, and train it on packaged <a href=https://www.kaggle.com/c/cifar-10>Cifar10</a> data. It then shows you how to upload your own image, and classify it into the 10 categories:\n",
    "\n",
    "airplane \n",
    "automobile \n",
    "bird \n",
    "cat \n",
    "deer \n",
    "dog \n",
    "frog \n",
    "horse \n",
    "ship \n",
    "truck\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/3649/media/cifar-10.png\">\n",
    "\n",
    "At the end of this tutorial, you should be able to upload your own images and classify them into one of the 10 categories.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have cells that prompt the user what to do (generate a backend...) and then a hidden/optional cell that shows the correct way if you get it wrong. \n",
    "\n",
    "The notebook server is going to run remotely on AWS, and you should have a piece of paper with a username and password on your desk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a model\n",
    "==================\n",
    "The pieces we need to set up a model are described in the <a href=http://neon.nervanasys.com/docs/latest/user_guide.html> user guide </a>:\n",
    "* CIFAR10 dataset \n",
    "* layer configuration and a <a href=http://neon.nervanasys.com/docs/latest/user_guide.html#model> model </a>\n",
    "* a compute <a href=http://neon.nervanasys.com/docs/latest/user_guide.html#backend-setup> backend </a>\n",
    "* an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<neon.backends.nervanagpu.NervanaGPU object at 0x7fa1eb57cd10>\n"
     ]
    }
   ],
   "source": [
    "# We start by generating the backend:\n",
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='gpu',             \n",
    "                 batch_size=128)\n",
    "\n",
    "# there is not much we can do with the backend right now, but if we\n",
    "# print it, it should tell us that we have a CPU backend object\n",
    "print be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a dataset\n",
    "-----------------\n",
    "Loading and generating datasets is explained in our documentation at http://neon.nervanasys.com/docs/latest/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dataset is supplied in canned form, and will be downloaded \n",
    "# from the web the first time you run this. It just returns numpy\n",
    "# arrays with the pixel values, and class labels. \n",
    "from neon.data import load_cifar10\n",
    "(X_train, y_train), (X_test, y_test), nclass = load_cifar10()\n",
    "\n",
    "# to put the dataset into a format neon can understand, we create\n",
    "# a DataIterator instance. This moves the data onto the compute\n",
    "# device (e.g. GPU) and provides an iterator that returns training\n",
    "# batches. \n",
    "from neon.data import DataIterator\n",
    "train_set = DataIterator(X_train, y_train, nclass=nclass, lshape=(3, 32, 32))\n",
    "test_set = DataIterator(X_test, y_test, nclass=nclass, lshape=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Layers\n",
    "--------------\n",
    "Layer types are explained in http://neon.nervanasys.com/docs/latest/layers.html\n",
    "It helps to make use of iPython tab completion to see available layers (e.g. from neon.layers import TAB) and to use the docstrings.\n",
    "\n",
    "Layer types include things such as\n",
    "* Convolution\n",
    "* Bias\n",
    "* Activation\n",
    "* Pooling\n",
    "* Batch Normalization\n",
    "and for commonly used combinations neon provides shortcuts:\n",
    "* Conv = Convolution + Bias + Activation\n",
    "* Affine = Linear + Bias + Activation\n",
    "\n",
    "for this network, we are going to use one Conv, one Pooling and one Affine layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/Extra credit: The ELU nonlinearity. This is supposed to speed up learning and show how to extend neon with custom code./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from neon.transforms.activation import Rectlin\n",
    "# class ELU(Rectlin):\n",
    "#     def __init__(self):\n",
    "#         name = \"ELU\"\n",
    "#         super(Rectlin, self).__init__(name)\n",
    "#         self.alpha = 1\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         return x if self.be.greater(x, 0) else self.alpha * (self.be.exp(x)-1)\n",
    "\n",
    "#     def bprop(self, x):\n",
    "#         return 1 if self.be.greater(x, 0) else self.alpha * (self.be.exp(x)-1) + self.alpha    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we create a model by assembling some layers\n",
    "from neon.layers import Conv, Affine, Pooling\n",
    "from neon.initializers import Uniform\n",
    "from neon.transforms.activation import Rectlin, Softmax\n",
    "init_uni = Uniform(low=-0.1, high=0.1)\n",
    "layers = [Conv(fshape=(5,5,16), init=init_uni, activation=Rectlin()),\n",
    "          Pooling(fshape=2, strides=2),\n",
    "          Conv(fshape=(5,5,32), init=init_uni, activation=Rectlin()),\n",
    "          Pooling(fshape=2, strides=2),\n",
    "          Affine(nout=500, init=init_uni, activation=Rectlin()),\n",
    "          Affine(nout=10, init=init_uni, activation=Softmax())]\n",
    "\n",
    "# set up model\n",
    "from neon.models import Model\n",
    "model = Model(layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function\n",
    "--------------\n",
    "Next we need a cost function to evaluate the output of the network. The cost function compares network outputs with ground truth labels, and produces and error that we can backpropagate through the layers of the network.\n",
    "\n",
    "Common cost functions are\n",
    "* Cross Entropy\n",
    "* Sum of squares difference\n",
    "\n",
    "For our binary classification task, we use crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the cost function\n",
    "from neon.layers import GeneralizedCost\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "---------\n",
    "We now have a cost function that we want to minimize, typically by following \n",
    "the negative gradient of the cost. This is called gradient descent. We do this\n",
    "iteratively over small batches of the data set, making it stochastic gradient \n",
    "decesent (SGD). There are other optimzers such as\n",
    "* RMSProp\n",
    "* AdaDelta\n",
    "\n",
    "that are supported in neon, but often simple gradient descent works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up optimizer\n",
    "from neon.optimizers import GradientDescentMomentum, RMSProp\n",
    "optimizer = GradientDescentMomentum(learning_rate=0.005, momentum_coef=0.9)\n",
    "#optimizer = RMSProp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks\n",
    "---------\n",
    "To provide feedback while the model is training, neon lets the user specify a set of callbacks that get evaluated at the end of every iteration (minibatch) or pass through the dataset (epoch). Callbacks include evaluating the model on a validation set or computing missclassification percentage. There are also callbacks for saving to disk and for generating visualizations. Here we will set up a progress bar to monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up callbacks. By default sets up a progress bar\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "callbacks = Callbacks(model, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "Now all the pieces are in place to run the network. We use the fit function and pass it a dataset, cost, optmizer, and the callbacks we set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   [Train |████████████████████|  391/391  batches, 1.59 cost, 0.96s]\n",
      "Epoch 1   [Train |████████████████████|  391/391  batches, 1.40 cost, 0.99s]\n",
      "Epoch 2   [Train |████████████████████|  390/390  batches, 1.31 cost, 0.99s]\n",
      "Epoch 3   [Train |████████████████████|  391/391  batches, 1.21 cost, 0.99s]\n",
      "Epoch 4   [Train |████████████████████|  390/390  batches, 1.15 cost, 0.98s]\n",
      "Epoch 5   [Train |████████████████████|  391/391  batches, 1.07 cost, 0.99s]\n",
      "Epoch 6   [Train |████████████████████|  391/391  batches, 1.01 cost, 0.99s]\n",
      "Epoch 7   [Train |████████████████████|  390/390  batches, 0.98 cost, 0.99s]\n",
      "Epoch 8   [Train |████████████████████|  391/391  batches, 0.93 cost, 0.99s]\n",
      "Epoch 9   [Train |████████████████████|  391/391  batches, 0.89 cost, 0.99s]\n",
      "Epoch 10  [Train |████████████████████|  390/390  batches, 0.84 cost, 0.98s]\n",
      "Epoch 11  [Train |████████████████████|  391/391  batches, 0.82 cost, 0.99s]\n",
      "Epoch 12  [Train |████████████████████|  390/390  batches, 0.78 cost, 0.99s]\n",
      "Epoch 13  [Train |████████████████████|  391/391  batches, 0.73 cost, 0.99s]\n",
      "Epoch 14  [Train |████████████████████|  391/391  batches, 0.75 cost, 0.99s]\n",
      "Epoch 15  [Train |████████████████████|  390/390  batches, 0.68 cost, 0.99s]\n",
      "Epoch 16  [Train |████████████████████|  391/391  batches, 0.67 cost, 1.00s]\n",
      "Epoch 17  [Train |████████████████████|  391/391  batches, 0.66 cost, 1.00s]\n",
      "Epoch 18  [Train |████████████████████|  390/390  batches, 0.65 cost, 0.99s]\n",
      "Epoch 19  [Train |████████████████████|  391/391  batches, 0.60 cost, 0.99s]\n",
      "Epoch 20  [Train |████████████████████|  390/390  batches, 0.55 cost, 0.99s]\n",
      "Epoch 21  [Train |████████████████████|  391/391  batches, 0.53 cost, 0.99s]\n",
      "Epoch 22  [Train |████████████████████|  391/391  batches, 0.51 cost, 0.99s]\n",
      "Epoch 23  [Train |████████████████████|  390/390  batches, 0.47 cost, 0.99s]\n",
      "Epoch 24  [Train |████████████████████|  391/391  batches, 0.46 cost, 0.99s]\n",
      "Epoch 25  [Train |████████████████████|  391/391  batches, 0.43 cost, 0.99s]\n",
      "Epoch 26  [Train |████████████████████|  390/390  batches, 0.43 cost, 0.99s]\n",
      "Epoch 27  [Train |████████████████████|  391/391  batches, 0.37 cost, 0.99s]\n",
      "Epoch 28  [Train |████████████████████|  390/390  batches, 0.36 cost, 0.99s]\n",
      "Epoch 29  [Train |████████████████████|  391/391  batches, 0.32 cost, 0.99s]\n",
      "Epoch 30  [Train |████████████████████|  391/391  batches, 0.31 cost, 0.99s]\n",
      "Epoch 31  [Train |████████████████████|  390/390  batches, 0.34 cost, 0.99s]\n",
      "Epoch 32  [Train |████████████████████|  391/391  batches, 0.32 cost, 0.99s]\n",
      "Epoch 33  [Train |████████████████████|  391/391  batches, 0.26 cost, 0.99s]\n",
      "Epoch 34  [Train |████████████████████|  390/390  batches, 0.25 cost, 0.99s]\n",
      "Epoch 35  [Train |████████████████████|  391/391  batches, 0.21 cost, 0.99s]\n",
      "Epoch 36  [Train |████████████████████|  390/390  batches, 0.18 cost, 0.99s]\n",
      "Epoch 37  [Train |████████████████████|  391/391  batches, 0.16 cost, 0.99s]\n",
      "Epoch 38  [Train |████████████████████|  391/391  batches, 0.18 cost, 0.99s]\n",
      "Epoch 39  [Train |████████████████████|  390/390  batches, 0.20 cost, 0.99s]\n"
     ]
    }
   ],
   "source": [
    "# And  run the model\n",
    "model.fit(dataset=train_set,\n",
    "          cost=cost,\n",
    "          optimizer=optimizer,\n",
    "          num_epochs=40,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, if you made it this far you have trained a convolutional network in neon.\n",
    "\n",
    "Evaluating the model\n",
    "--------------------\n",
    "We can now compute the misclassification on the test set to see how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification error = 40.4%\n"
     ]
    }
   ],
   "source": [
    "# Check the performance on the supplied test set\n",
    "from neon.transforms import Misclassification\n",
    "print 'Misclassification error = %.1f%%' % (model.eval(test_set, metric=Misclassification())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tweaking some of the hyperparameters (number of layers, adding dropout...) we can improve the performance.\n",
    "\n",
    "This was quite a lot of code! Generally, to set up a new model from scratch it is best to follow one of the examples from the neon/examples directory. It's easy to mix and match parts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Visualizations\n",
    "--------------\n",
    "But first, lets look at whats going on inside the model. For this we will use matplotlib to make some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (75, 16)\n",
      "[[ 0.28793609 -0.06150856  0.11460879 ..., -0.08780234  0.35006201\n",
      "  -0.24346967]\n",
      " [ 0.31608564  0.26100114 -0.15777992 ..., -0.12366543  0.04897519\n",
      "  -0.19653422]\n",
      " [-0.10796933  0.38127381 -0.32522649 ..., -0.11146627 -0.27418122\n",
      "  -0.20478141]\n",
      " ..., \n",
      " [ 0.2227913   0.35168371  0.59361702 ...,  0.14048272  0.46139881\n",
      "   0.06821094]\n",
      " [-0.06844849  0.17166287  0.55679786 ..., -0.0227278   0.08557089\n",
      "   0.1152233 ]\n",
      " [-0.14400844 -0.03177495  0.40571338 ..., -0.04805142 -0.23483859\n",
      "   0.06853524]]\n",
      "min -1.46263\n",
      "[[ 1.75056207  1.40111744  1.57723475 ...,  1.37482369  1.81268799\n",
      "   1.21915627]\n",
      " [ 1.77871156  1.72362709  1.30484605 ...,  1.33896053  1.51160121\n",
      "   1.26609182]\n",
      " [ 1.3546567   1.84389973  1.13739944 ...,  1.35115969  1.18844473\n",
      "   1.25784457]\n",
      " ..., \n",
      " [ 1.68541729  1.81430972  2.05624294 ...,  1.60310864  1.92402482\n",
      "   1.53083694]\n",
      " [ 1.39417744  1.63428879  2.01942396 ...,  1.43989813  1.54819691\n",
      "   1.57784927]\n",
      " [ 1.31861758  1.43085098  1.8683393  ...,  1.41457462  1.22778738\n",
      "   1.53116119]]\n",
      "max 2.77279\n",
      "[[ 0.63133627  0.50530982  0.56882614 ...,  0.49582705  0.65374184\n",
      "   0.43968594]\n",
      " [ 0.64148831  0.6216222   0.47058979 ...,  0.48289308  0.54515558\n",
      "   0.45661315]\n",
      " [ 0.48855388  0.66499829  0.41020054 ...,  0.48729268  0.42860991\n",
      "   0.45363879]\n",
      " ..., \n",
      " [ 0.60784191  0.65432668  0.74157935 ...,  0.57815748  0.69389522\n",
      "   0.55209291]\n",
      " [ 0.50280696  0.58940256  0.72830069 ...,  0.51929599  0.55835372\n",
      "   0.56904775]\n",
      " [ 0.47555646  0.51603317  0.67381233 ...,  0.51016313  0.44279873\n",
      "   0.55220979]]\n",
      "[[ 160.99075317  128.85400391  145.05065918 ...,  126.43589783  166.7041626\n",
      "   112.11991119]\n",
      " [ 163.57951355  158.51365662  120.00039673 ...,  123.13773346\n",
      "   139.01467896  116.43635559]\n",
      " [ 124.58123779  169.5745697   104.60113525 ...,  124.25963593  109.2955246\n",
      "   115.67789459]\n",
      " ..., \n",
      " [ 154.99967957  166.853302    189.10273743 ...,  147.43016052\n",
      "   176.94328308  140.78369141]\n",
      " [ 128.21577454  150.2976532   185.7166748  ...,  132.42047119\n",
      "   142.38020325  145.10717773]\n",
      " [ 121.26689911  131.5884552   171.82214355 ...,  130.09159851  112.9136734\n",
      "   140.81349182]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAD7CAYAAADq4RYlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1a59deed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "weights = model.layers.layers[0].W.get()\n",
    "print \"shape\", weights.shape\n",
    "print weights\n",
    "print \"min\", weights.min()\n",
    "weights = weights - weights.min()\n",
    "print weights\n",
    "print \"max\", weights.max()\n",
    "weights = weights / weights.max()\n",
    "print weights\n",
    "weights = 255. * weights\n",
    "print weights\n",
    "for feature in range(16):\n",
    "    f_map = weights[:,feature].reshape(3,5,5).transpose((1,2,0))\n",
    "\n",
    "    f_map = weights[:,feature].reshape(5,5,3)\n",
    "\n",
    "    plt.subplot(4,4,feature+1)\n",
    "    plt.imshow(f_map, interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference\n",
    "=========\n",
    "Now we want to grab a new image from the internet and classify it through our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD9CAYAAACcAsr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZHwhHCLjC+EQGV8Ih8j4QjhExhfCIf8NlzVDdiCkWPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1a598e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# an image of a from I found on Wikipedia\n",
    "img_source = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Atelopus_zeteki1.jpg/440px-Atelopus_zeteki1.jpg\"\n",
    "img_source = \"https://upload.wikimedia.org/wikipedia/commons/d/de/Nokota_Horses_cropped.jpg\"\n",
    "# download the image\n",
    "import urllib\n",
    "urllib.urlretrieve(img_source, filename=\"frog.jpg\")\n",
    "\n",
    "# crop and resize to 32x32\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('frog.jpg')\n",
    "crop = img.crop((0,0,min(img.size),min(img.size)))\n",
    "crop.thumbnail((32, 32))\n",
    "plt.imshow(crop, interpolation=\"nearest\")  # crop or img\n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new backend with a batch size of 1 for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a minibatch with the new image \n",
    "import numpy as np\n",
    "x_new = np.zeros((128,3072), dtype=np.float32)\n",
    "x_new[0] = np.asarray(crop, dtype=np.float32).flatten().reshape(1,3072)/ 255\n",
    "\n",
    "inference_set = DataIterator(x_new, None, nclass=nclass, lshape=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes =[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "out = model.get_outputs(inference_set)\n",
    "classes[out[0].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
