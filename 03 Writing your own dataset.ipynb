{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a custom dataset\n",
    "This notebook will walk you through implementing a custom iterator for a modified version of the Street View House Number (SVHN) dataset. You will then design a network to train on this dataset. \n",
    "\n",
    "## SVHN dataset\n",
    "\n",
    "This dataset is a collection of 73,257 images of house numbers collected from Google Streetview. The original dataset has bounding boxes for all the digits in the image:\n",
    "\n",
    "<img src=\"http://ufldl.stanford.edu/housenumbers/examples_new.png\" width=500px>\n",
    "\n",
    "We have modified the dataset such that each image is 64x64 pixels (with 3 color channels), and the target is a *single* bounding box over all the digits. Your goal is to build a network that, given an image, returns bounding box coordinates for the location of the digit sequence.\n",
    "\n",
    "This notebook is split into two parts:\n",
    "* Writing a custom dataiterator\n",
    "* Building a prediction network\n",
    "\n",
    "## Custom dataset\n",
    "\n",
    "Because the training set of ~27,000 images can fit into the memory of a single Titan X GPU, we could use the `ArrayIterator` class to provide data to the model. However, when the dataset may have more images or larger image sizes, that is no longer an option. Our high-performance `DataLoader`, which loads image in batches and performs complex augmentation, cannot currently handle bounding box data (stay tuned, an object localization dataloader is coming in a future neon release!).\n",
    "\n",
    "We've saved the dataset as a pickle file `svhn_64_box_truncated.p`. This file has a few variables:\n",
    "- `X_train`: a numpy array of shape `(num_examples, num_features)`, where `num_examples = 26624`, and `num_features = 3*64*64 = 12288`\n",
    "- `y_train`: a numpy array of shape `(num_examples, 4)`, with the target bounding box coordinates in `(x_min, y_min, w, h)` format.\n",
    "\n",
    "Let's first import our backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.backends import gen_backend\n",
    "\n",
    "be = gen_backend(batch_size=128, backend='gpu')\n",
    "\n",
    "# set the debug level to 10 (the minimum)\n",
    "# to see all the output\n",
    "import logging\n",
    "main_logger = logging.getLogger('neon')\n",
    "main_logger.setLevel(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below is a skeleton of the SVHN data iterator for you to fill out, with notes to help along the way. The goal is an object that returns, with each call, a tuple of `(X, Y)`, where:\n",
    "- `X`: tensor of shape (num_features, batch_size)\n",
    "- `Y`: tensor of shape (4, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some useful packages\n",
    "from neon.data import NervanaDataIterator\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import os\n",
    "\n",
    "class SVHN(NervanaDataIterator):\n",
    "\n",
    "    def __init__(self, set_name=\"train\"):\n",
    "\n",
    "        # load data from pickle file\n",
    "        with open('data/svhn_64.p') as f:\n",
    "            data = cPickle.load(f)\n",
    "\n",
    "        # Load the numpy data into some variables. We divide the image by 255 to normalize the values\n",
    "        # between 0 and 1.\n",
    "        self.X = data['X_' + set_name] / 255.\n",
    "        self.Y = data['y_' + set_name]\n",
    "        \n",
    "        # 1. allocate memory on the GPU for a minibatch's worth of data.\n",
    "        # (e.g. use `self.be` to access the backend.). See the backend documentation.\n",
    "        ...\n",
    "\n",
    "\n",
    "        # 2. assign some required attributes\n",
    "        self.start = 0  # start at zero\n",
    "        self.ndata = ...# number of examples\n",
    "        self.nbatches = ...# number of minibatches per epoch\n",
    "        self.shape = ...# shape of the input (e.g. for images, (C, H, W))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 3. loop through minibatches in the dataset\n",
    "        for .... :\n",
    "            # 3a. grab the right slice from the numpy arrays\n",
    "            ...\n",
    "            \n",
    "            # 3b. transfer from numpy arrays to device\n",
    "            # - use the GPU memory buffers allocated previously,\n",
    "            # and call the myTensorBuffer.set() function. \n",
    "            # - note: the numpy arrays need in contiguous before being loaded\n",
    "            # onto the device. use `np.ascontiguousarray(..)` to ensure that this\n",
    "            # is the case!\n",
    "            ...\n",
    "            \n",
    "            # 3c. yield a tuple of inputs and targets.\n",
    "            # inputs should be of shape (num_features, batch_size)\n",
    "            # targets should be of shape (4, batch_size)\n",
    "            yield (..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your implementation! Below we grab an iteration and print out the output of the dataset. Importantly: make sure that the output tensors are contiguous (e.g. `is_contiguous = True` in the output below). This means that they are allocated on a contiguous set of memory, which is important for the downstream calculations. Contiguity can be broken by operations like transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup datasets\n",
    "train_set = SVHN(set_name=\"train\")\n",
    "\n",
    "# grab one iteration from the train_set\n",
    "iterator = train_set.__iter__()\n",
    "(X, Y) = iterator.next()\n",
    "print X\n",
    "print Y\n",
    "assert X.is_contiguous\n",
    "assert Y.is_contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If all goes well, you are ready to try training on this network! First, let's reset the dataset to zero (since you drew one example from above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "To get you started, below we use a toy example that reaches ?? cost after 10 epochs. But you can do better! Play around with adding more layers. \n",
    "\n",
    "If you are feeling ambitious, you can delete the below and try to build a model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.initializers import Gaussian\n",
    "from neon.layers import GeneralizedCost, Affine, Conv, Pooling, Linear, Dropout\n",
    "from neon.models import Model\n",
    "from neon.optimizers import GradientDescentMomentum, RMSProp\n",
    "from neon.transforms import Rectlin, Logistic, CrossEntropyMulti, Misclassification, SumSquared\n",
    "\n",
    "init_norm = Gaussian(loc=0.0, scale=0.01)\n",
    "\n",
    "# set up model layers\n",
    "conv = dict(init=init_norm, batch_norm=True, activation=Rectlin())\n",
    "convp1 = dict(init=init_norm, batch_norm=True, activation=Rectlin(), padding=1)\n",
    "\n",
    "layers = [Conv((3, 3, 64), **convp1),  # 64x64 feature map\n",
    "          Conv((3, 3, 64), **convp1),\n",
    "          Pooling((2, 2)),\n",
    "          Dropout(keep=.5),\n",
    "          Conv((3, 3, 96), **convp1),  # 32x32 feature map\n",
    "          Conv((3, 3, 96), **convp1),\n",
    "#           Pooling((2, 2)),\n",
    "#           Dropout(keep=.5),\n",
    "#           Conv((3, 3, 128), **convp1),  # 16x16 feature map\n",
    "#           Conv((3, 3, 128), **convp1),\n",
    "#           Pooling((2, 2)),\n",
    "#           Dropout(keep=.5),\n",
    "#           Conv((3, 3, 192), **convp1),  # 8x8 feature map\n",
    "#           Conv((1, 1, 192), **conv),\n",
    "          Linear(nout=4, init=init_norm)] # last layer good for bbox\n",
    "\n",
    "# use SumSquared cost\n",
    "cost = GeneralizedCost(costfunc=SumSquared())\n",
    "\n",
    "# setup optimizer\n",
    "optimizer = RMSProp()\n",
    "\n",
    "# initialize model object\n",
    "mlp = Model(layers=layers)\n",
    "\n",
    "# configure callbacks\n",
    "callbacks = Callbacks(mlp)\n",
    "\n",
    "# run fit\n",
    "mlp.fit(train_set, optimizer=optimizer, num_epochs=10, cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To understand how the network performed, we sample an image and plot the network's predicted bounding box against the ground truth bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a minibatch's worth of\n",
    "# inputs (X) and targets (T)\n",
    "iterator = train_set.__iter__()\n",
    "(X, T) = iterator.next()\n",
    "\n",
    "# fprop the input to get the model output\n",
    "y = mlp.fprop(X)\n",
    "\n",
    "# transfer from device to numpy arrays\n",
    "y = y.get()\n",
    "T = T.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ground truth box `T` and the model prediction `y` are both arrays of size `(4, batch_size)`. We can plot the first image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Target box had coordinates: {}\".format(T[:,0])\n",
    "print \"Model prediction has coordinates: {}\".format(y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "plt.imshow(X.get()[:, i].reshape(3, 64, 64).transpose(1, 2, 0))\n",
    "ax = plt.gca()\n",
    "ax.add_patch(plt.Rectangle((y[0,i], y[1,i]), y[2,i], y[3,i], fill=False, edgecolor=\"red\")) # model guess\n",
    "ax.add_patch(plt.Rectangle((T[0,i], T[1,i]), T[2,i], T[3,i], fill=False, edgecolor=\"blue\")) # ground truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
