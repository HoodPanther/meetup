{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a new layer\n",
    "\n",
    "This tutorial is similar to the model specified in `examples/mnist_mlp.py`.\n",
    "\n",
    "## Preamble\n",
    "The first step is to set up our compute backend, and initialize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import neon\n",
    "print neon.__version__\n",
    "\n",
    "from neon.backends import gen_backend\n",
    "be = gen_backend('gpu', batch_size=128)\n",
    "\n",
    "from neon.data import load_mnist\n",
    "from neon.data import ArrayIterator\n",
    "\n",
    "# download or reuse cached data\n",
    "(X_train, y_train), (X_test, y_test), nclass = load_mnist()\n",
    "\n",
    "# setup training and test set iterator\n",
    "train_set = ArrayIterator(X_train, y_train, nclass=nclass)\n",
    "test_set = ArrayIterator(X_test, y_test, nclass=nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new functionality\n",
    "We demonstrate through simple examples how to add an activation function and layer to neon.\n",
    "\n",
    "### Build your own layer\n",
    "Instead of importing the neon supplied 'Affine' Layer, we will build our own.\n",
    "\n",
    "Note- Affine is a 'container' layer- meaning it bundles real layer with an activation and batch normalization layers.  The real layer inside of Affine is a 'Linear' layer which implements a fully connected MLP layer.  \n",
    "\n",
    "First, lets build a linear layer, and then we will wrap it in an affine container.\n",
    "\n",
    "In the implementation below, fprop is implemented using element-wise operations.  It will be very slow.  Try replacing it with the neon backend implementation of compound_dot, like in the bprop function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.layers.layer import ParameterLayer, interpret_in_shape\n",
    "\n",
    "class MyLinear(ParameterLayer):\n",
    "\n",
    "    def __init__(self, nout, init, name=None):\n",
    "        super(MyLinear, self).__init__(init, name, \"Disabled\")\n",
    "        self.nout = nout\n",
    "        self.inputs = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Linear Layer '%s': %d inputs, %d outputs\" % (\n",
    "               self.name, self.nin, self.nout)\n",
    "\n",
    "    def configure(self, in_obj):\n",
    "        \"\"\"\n",
    "        Define some sizes that get used by the allocate method inherited from Layer.\n",
    "        \"\"\"\n",
    "        super(MyLinear, self).configure(in_obj)\n",
    "        \n",
    "        (self.nin, self.nsteps) = interpret_in_shape(self.in_shape)\n",
    "        \n",
    "        self.out_shape = (self.nout, self.nsteps)\n",
    "        if self.weight_shape is None:\n",
    "            self.weight_shape = (self.nout, self.nin)\n",
    "      \n",
    "        return self\n",
    "\n",
    "    def fprop(self, inputs, inference=False, beta=0.0):\n",
    "        self.inputs = inputs\n",
    "\n",
    "        for r in range(self.outputs.shape[0]):\n",
    "            for c in range(self.outputs.shape[1]):\n",
    "                self.outputs[r,c] = self.be.sum(self.be.multiply(self.W[r], self.inputs[:,c].T))\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "    def bprop(self, error, alpha=1.0, beta=0.0):\n",
    "        if self.deltas:\n",
    "            self.be.compound_dot(A=self.W.T, B=error, C=self.deltas, alpha=alpha, beta=beta)\n",
    "        self.be.compound_dot(A=error, B=self.inputs.T, C=self.dW)\n",
    "        return self.deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the raw layer in a container, which bundles an activation and batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.layers.layer import CompoundLayer\n",
    "class MyAffine(CompoundLayer):\n",
    "\n",
    "    def __init__(self, nout, init, bias=None,\n",
    "                 batch_norm=False, activation=None, name=None):\n",
    "        super(MyAffine, self).__init__(bias=bias, activation=activation, name=name)\n",
    "        self.append(MyLinear(nout, init, name=name))\n",
    "        self.add_postfilter_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an activation function (transform)\n",
    "\n",
    "We can play with more of the backend element-wise functions with this example.\n",
    "\n",
    "Implement the Softmax function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.transforms.transform import Transform\n",
    "\n",
    "class MySoftmax(Transform):\n",
    "    \"\"\"\n",
    "    SoftMax activation function. Ensures that the activation output sums to 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, name=None, epsilon=2**-23):\n",
    "        \"\"\"\n",
    "        Class constructor.\n",
    "        Arguments:\n",
    "            name (string, optional): Name (default: none)\n",
    "            epsilon (float, optional): Not used.\n",
    "        \"\"\"\n",
    "        super(MySoftmax, self).__init__(name)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Implement the softmax function.\n",
    "        \"\"\"\n",
    "        return (self.be.reciprocal(self.be.sum(\n",
    "                self.be.exp(x - self.be.max(x, axis=0)), axis=0)) *\n",
    "                self.be.exp(x - self.be.max(x, axis=0)))\n",
    "\n",
    "    def bprop(self, x):\n",
    "        \"\"\"\n",
    "        We take a shortcut here- the derivative cancels out with the CrossEntropy term.\n",
    "        \"\"\"\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting together all of the pieces\n",
    "The architecture here is the same as in the mnist_mlp.py example.  In summary, 2 fully connected layers, one larger hidden layer with rectified linear units and one the size of the number of output classes with a softmax.\n",
    "\n",
    "Use our activation and layer rather than the neon provided ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.initializers import Gaussian\n",
    "from neon.models import Model\n",
    "from neon.transforms.activation import Rectlin\n",
    "\n",
    "init_norm = Gaussian(loc=0.0, scale=0.01)\n",
    "\n",
    "# assemble all of the pieces\n",
    "layers = []\n",
    "layers.append(MyAffine(nout=100, init=init_norm, activation=Rectlin()))\n",
    "layers.append(MyAffine(nout=10, init=init_norm, activation=MySoftmax()))\n",
    "\n",
    "# initialize model object\n",
    "mlp = Model(layers=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n",
    "Using Cross Entropy loss and Gradient Descent optimizer, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.layers import GeneralizedCost\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "from neon.optimizers import GradientDescentMomentum\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())\n",
    "optimizer = GradientDescentMomentum(0.1, momentum_coef=0.9)\n",
    "callbacks = Callbacks(mlp, eval_set=test_set)\n",
    "\n",
    "mlp.fit(train_set, optimizer=optimizer, num_epochs=10, cost=cost,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the fitting procedure, neon propagates train_set through the model to set the input and output shapes of each layer. Each layer has a configure() method that determines the appropriate layer shapes, and an allocate() method to set up the needed buffers for holding the forward propagation information.\n",
    "\n",
    "During the training, neon sends batches of the training data through the model, calling each layersâ€™ fprop() and bprop() methods to compute the gradients and update the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained model\n",
    "Now that the model is successfully trained, we can use the trained model to classify a novel image, measure performance, and visualize the weights and training results.\n",
    "\n",
    "#### Inference\n",
    "Given a set of images such as those contained in the iterable test_set, we can fetch the ouput of the final model layer via\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = mlp.get_outputs(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable results is a numpy array with shape (num_test_examples, num_outputs) = (10000,10) with the model probabilities for each label.\n",
    "\n",
    "#### Performance\n",
    "Neon supports convenience functions for evaluating performance using custom metrics. Here we measure the misclassification rate on the held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.transforms import Misclassification\n",
    "\n",
    "# evaluate the model on test_set using the misclassification metric\n",
    "error = mlp.eval(test_set, metric=Misclassification())*100\n",
    "print('Misclassification error = %.1f%%' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
